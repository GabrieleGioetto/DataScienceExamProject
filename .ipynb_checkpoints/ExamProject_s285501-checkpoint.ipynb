{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"competition_dataset/dev.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(df[pd.isna(df[\"region_1\"]) & pd.isna(df[\"region_2\"])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "print(df[\"designation\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(df[\"designation\"].value_counts()[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#df[df[\"designation_tr\"] == \"reserva\" | df[\"designation_tr\"] == \"riserva\" | df[\"designation_tr\"] == \"rèserve\"][\"designation_tr\"] = \"reserve\"\n",
    "df[\"designation_tr\"] = df[\"designation\"].apply(lambda d: d.lower() if pd.isna(d) == False else d)\n",
    "df[\"designation_tr\"] = df[\"designation_tr\"].replace([\"reserva\",\"riserva\",\"rèserve\"],[\"reserve\",\"reserve\",\"reserve\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# rimuovo regioni doppie e creo regione unica\n",
    "df.loc[df[\"region_1\"] == df[\"region_2\"], \"region_2\"] = \"\"\n",
    "df[\"region_complete\"] = df[[\"region_1\",\"region_2\"]].fillna(\" \").agg(' '.join, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "singular_region_complete = set(df[\"region_complete\"])\n",
    "len(singular_region_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import geocoder\n",
    "\n",
    "g = geocoder.arcgis('Redlands, CA')\n",
    "print(g.latlng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "import geocoder\n",
    "\n",
    "singular_region_complete_with_latlong = []\n",
    "for region in singular_region_complete:\n",
    "    print(region)\n",
    "    loc =  geocoder.arcgis(region,maxRows=1)\n",
    "    print(loc)\n",
    "    try:\n",
    "        singular_region_complete_with_latlong.append((region, loc.latlng[0],loc.latlng[1]))   \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with open('region_coordinates.csv', 'w') as fp:\n",
    "    fp.write('\\n'.join('%s,%f,%f' % x for x in singular_region_complete_with_latlong))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_region_coordinates = pd.read_csv('region_coordinates.csv')\n",
    "\n",
    "df = pd.merge(df, df_region_coordinates, how=\"left\", on=\"region_complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.to_csv(\"competition_dataset/mine_dev.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = pd.get_dummies(df, columns=[\"designation_tr\",\"province\",\"variety\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"competition_dataset/mine_dev.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    df[\"designation_tr\"].value_counts()[:200]\n",
    "    \n",
    "len(df[\"designation_tr\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import gmaps\n",
    "import gmaps.datasets\n",
    "from ipywidgets.embed import embed_minimal_html\n",
    "\n",
    "locations = df[['lat', 'long']]\n",
    "weights = df['quality']\n",
    "fig = gmaps.figure()\n",
    "heatmap_layer = gmaps.heatmap_layer(locations, weights=weights)\n",
    "fig.add_layer(heatmap_layer)\n",
    "embed_minimal_html('export.html', views=[fig])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "df[\"variety\"].value_counts()[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "df[\"province\"].value_counts()[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df[\"region_complete\"] = df[\"region_complete\"].replace(r'^\\s*$', np.NaN, regex=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = pd.get_dummies(df, columns=[\"region_complete\",\"variety\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.to_csv(\"competition_dataset/mine_dev_with_dummies.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = pd.read_csv(\"competition_dataset/mine_dev_with_dummies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from platform import python_version\n",
    "\n",
    "print(python_version())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing su x\n",
    "df = pd.read_csv(\"competition_dataset/dev.tsv\", sep=\"\\t\")\n",
    "\n",
    "df = df.drop(df[df[\"quality\"] == 0].index) #Rimuovo righe con qualità uguale a zero ( sono solo 15 in totale )\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df[\"designation_tr\"] = df[\"designation\"].apply(lambda d: d.lower() if pd.isna(d) == False else d)\n",
    "df[\"designation_tr\"] = df[\"designation_tr\"].replace([\"reserva\",\"riserva\",\"réserve\"],[\"reserve\",\"reserve\",\"reserve\"])\n",
    "\n",
    "df.loc[df[\"region_1\"] == df[\"region_2\"], \"region_2\"] = \"\"\n",
    "df[\"region_complete\"] = df[[\"region_1\",\"region_2\"]].fillna(\" \").agg(' '.join, axis=1)\n",
    "df[\"region_complete\"] = df[\"region_complete\"].replace(r'^\\s*$', np.NaN, regex=True)\n",
    "\n",
    "df[\"description_len\"] = df[\"description\"].map(len)\n",
    "\n",
    "df[\"region_complete\"].fillna('None', inplace=True)\n",
    "df[\"variety\"].fillna('None', inplace=True)\n",
    "df[\"country\"].fillna('None', inplace=True)\n",
    "df[\"winery\"].fillna('None', inplace=True)\n",
    "df[\"designation_tr\"].fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing su x_eval\n",
    "\n",
    "df_eval = pd.read_csv(\"competition_dataset/eval.tsv\", sep=\"\\t\")\n",
    "\n",
    "df_eval[\"designation_tr\"] = df_eval[\"designation\"].apply(lambda d: d.lower() if pd.isna(d) == False else d)\n",
    "df_eval[\"designation_tr\"] = df_eval[\"designation_tr\"].replace([\"reserva\",\"riserva\",\"rèserve\"],[\"reserve\",\"reserve\",\"reserve\"])\n",
    "\n",
    "df_eval.loc[df_eval[\"region_1\"] == df_eval[\"region_2\"], \"region_2\"] = \"\"\n",
    "df_eval[\"region_complete\"] = df_eval[[\"region_1\",\"region_2\"]].fillna(\" \").agg(' '.join, axis=1)\n",
    "df_eval[\"region_complete\"] = df_eval[\"region_complete\"].replace(r'^\\s*$', np.NaN, regex=True)\n",
    "\n",
    "df_eval[\"description_len\"] = df_eval[\"description\"].map(len)\n",
    "\n",
    "df_eval[\"region_complete\"].fillna('None', inplace=True)\n",
    "df_eval[\"variety\"].fillna('None', inplace=True)\n",
    "df_eval[\"country\"].fillna('None', inplace=True)\n",
    "df_eval[\"winery\"].fillna('None', inplace=True)\n",
    "df_eval[\"designation_tr\"].fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Aggiungo a x i bit delle winery con più vini\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df_group_by_winery = df[[\"winery\",\"quality\"]].groupby(by=\"winery\",sort=True).agg(['mean', 'count']).sort_values(by=(\"quality\",\"count\"),ascending=False)\n",
    "df_group_by_winery[df_group_by_winery[(\"quality\",\"count\")] >= 30]\n",
    "\n",
    "top_N_winery = df_group_by_winery[df_group_by_winery[(\"quality\",\"count\")] >= 30].index.values\n",
    "\n",
    "df.loc[~df[\"winery\"].isin(top_N_winery) ,\"winery\"] = \"None\"\n",
    "\n",
    "ohc_w = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "ohWinery = ohc_w.fit_transform(df[\"winery\"].values.reshape(-1,1)).toarray()\n",
    "dfOneHot_w = pd.DataFrame(ohWinery, columns=[\"winery_tr_\" + str(ohc_w.categories_[0][i]) for i in range(len(ohc_w.categories_[0]))])\n",
    "\n",
    "df = pd.concat([df,dfOneHot_w], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Aggiungo a x_eval i bit delle winery con più vini\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohWinery = ohc_w.transform(df_eval[\"winery\"].values.reshape(-1,1)).toarray()\n",
    "dfOneHot_w = pd.DataFrame(ohWinery, columns=[\"winery_tr_\" + str(ohc_w.categories_[0][i]) for i in range(len(ohc_w.categories_[0]))])\n",
    "\n",
    "df_eval = pd.concat([df_eval,dfOneHot_w], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column=['quality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Aggiungo coordinate lat long a x\n",
    "df_region_coordinates = pd.read_csv('region_coordinates.csv')\n",
    "\n",
    "df = pd.merge(df, df_region_coordinates, how=\"left\", on=\"region_complete\")\n",
    "\n",
    "print(df.columns)\n",
    "lat_mean = df['lat'].mean()\n",
    "long_mean = df['long'].mean()\n",
    "\n",
    "df[\"lat\"].fillna(lat_mean, inplace=True)\n",
    "df[\"long\"].fillna(long_mean, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Aggiungo coordinate lat long a x_eval\n",
    "df_region_coordinates = pd.read_csv('region_coordinates.csv')\n",
    "\n",
    "df_eval = pd.merge(df_eval, df_region_coordinates, how=\"left\", on=\"region_complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggiungo a x bit di encoding di region_complete e variety e country\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohc_r = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "ohc_v = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "ohc_c = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "ohRegion = ohc_r.fit_transform(df[\"region_complete\"].values.reshape(-1,1)).toarray()\n",
    "ohVariety = ohc_v.fit_transform(df[\"variety\"].values.reshape(-1,1)).toarray()\n",
    "ohCountry = ohc_c.fit_transform(df[\"country\"].values.reshape(-1,1)).toarray()\n",
    "\n",
    "dfOneHot_r = pd.DataFrame(ohRegion, columns=[\"region_complete_\" + str(ohc_r.categories_[0][i]) for i in range(len(ohc_r.categories_[0]))])\n",
    "dfOneHot_v = pd.DataFrame(ohVariety, columns=[\"variety_\" + str(ohc_v.categories_[0][i]) for i in range(len(ohc_v.categories_[0]))])\n",
    "dfOneHot_c = pd.DataFrame(ohCountry, columns=[\"country_\" + str(ohc_c.categories_[0][i]) for i in range(len(ohc_c.categories_[0]))])\n",
    "\n",
    "df = pd.concat([df,dfOneHot_r,dfOneHot_v, dfOneHot_c], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120729, 2733) (30186, 2732)\n"
     ]
    }
   ],
   "source": [
    "# Aggiungo a x_eval bit di encoding di region_complete e variety e country\n",
    "\n",
    "ohRegion = ohc_r.transform(df_eval[\"region_complete\"].values.reshape(-1,1)).toarray()\n",
    "ohVariety = ohc_v.transform(df_eval[\"variety\"].values.reshape(-1,1)).toarray()\n",
    "ohCountry = ohc_c.transform(df_eval[\"country\"].values.reshape(-1,1)).toarray()\n",
    "\n",
    "dfOneHot_r = pd.DataFrame(ohRegion, columns=[\"region_complete_\" + str(ohc_r.categories_[0][i]) for i in range(len(ohc_r.categories_[0]))])\n",
    "dfOneHot_v = pd.DataFrame(ohVariety, columns=[\"variety_\" + str(ohc_v.categories_[0][i]) for i in range(len(ohc_v.categories_[0]))])\n",
    "dfOneHot_c = pd.DataFrame(ohCountry, columns=[\"country_\" + str(ohc_c.categories_[0][i]) for i in range(len(ohc_c.categories_[0]))])\n",
    "\n",
    "df_eval = pd.concat([df_eval,dfOneHot_r,dfOneHot_v,dfOneHot_c], axis=1)\n",
    "\n",
    "print(df.shape, df_eval.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_group_by_designation_tr = df[[\"designation_tr\",\"quality\"]].groupby(by=\"designation_tr\",sort=True).agg(['mean','count'])\n",
    "df_group_by_designation_tr.reset_index()\n",
    "df_group_by_designation_tr = df_group_by_designation_tr[df_group_by_designation_tr[(\"quality\",\"count\")] >= 10]\n",
    "\n",
    "df_group_by_designation_tr.drop([\"None\"], inplace=True)\n",
    "\n",
    "df_group_by_designation_tr.columns = df_group_by_designation_tr.columns.droplevel(0)\n",
    "df_group_by_designation_tr.drop(columns=[\"count\"], inplace=True)\n",
    "df_group_by_designation_tr.columns = [\"designation_tr_quality_mean\"]\n",
    "\n",
    "df_group_by_designation_tr\n",
    "#df = pd.merge(df, df_group_by_designation_tr, how=\"left\", on=\"designation_tr\")\n",
    "\n",
    "df_test = pd.merge(df, df_group_by_designation_tr, how=\"left\", on=\"designation_tr\")\n",
    "\n",
    "df_test[\"designation_tr_quality_mean\"].fillna(-1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggiungo a x i chunks delle designation\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df_group_by_designation_tr = df[[\"designation_tr\",\"quality\"]].groupby(by=\"designation_tr\",sort=True).agg(['mean','count'])\n",
    "df_group_by_designation_tr.reset_index()\n",
    "df_group_by_designation_tr = df_group_by_designation_tr[df_group_by_designation_tr[(\"quality\",\"count\")] >= 10]\n",
    "\n",
    "df_group_by_designation_tr.drop([\"None\"], inplace=True)\n",
    "\n",
    "df_group_by_designation_tr.columns = df_group_by_designation_tr.columns.droplevel(0)\n",
    "df_group_by_designation_tr.drop(columns=[\"count\"], inplace=True)\n",
    "df_group_by_designation_tr.columns = [\"desi_quality_mean\"]\n",
    "\n",
    "\n",
    "df = pd.merge(df, df_group_by_designation_tr, how=\"left\", on=\"designation_tr\")\n",
    "df[\"desi_quality_mean\"].fillna(-1, inplace=True)\n",
    "df[\"desi_quality_mean\"] = df[\"desi_quality_mean\"].astype(int)\n",
    "\n",
    "ohc_d = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "ohDesignation_quality_mean = ohc_d.fit_transform(df[\"desi_quality_mean\"].values.reshape(-1,1)).toarray()\n",
    "\n",
    "dfOneHot_dq = pd.DataFrame(ohDesignation_quality_mean, columns=[\"desi_quality_mean_\" + str(ohc_d.categories_[0][i]) for i in range(len(ohc_d.categories_[0]))])\n",
    "\n",
    "df.drop(columns=[\"desi_quality_mean\"], inplace=True)\n",
    " \n",
    "df = pd.concat([df,dfOneHot_dq], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggiungo a x_eval i chunks delle designation\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df_eval = pd.merge(df_eval, df_group_by_designation_tr, how=\"left\", on=\"designation_tr\")\n",
    "\n",
    "df_eval[\"desi_quality_mean\"] = df_eval[\"desi_quality_mean\"].fillna(-1)\n",
    "\n",
    "ohDesignation_quality_mean = ohc_d.transform(df_eval[\"desi_quality_mean\"].values.reshape(-1,1)).toarray()\n",
    "\n",
    "dfOneHot_dq = pd.DataFrame(ohDesignation_quality_mean, columns=[\"desi_quality_mean_\" + str(ohc_d.categories_[0][i]) for i in range(len(ohc_d.categories_[0]))])\n",
    "\n",
    "df_eval.drop(columns=[\"desi_quality_mean\"], inplace=True)\n",
    "\n",
    "df_eval = pd.concat([df_eval,dfOneHot_dq], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggiungo i bit dei primi N designation a x\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "N = 300 top_N_designation_tr = list(df[\"designation_tr\"].value_counts()[1:N+1].keys()) #non includo None values\n",
    "\n",
    "df.loc[~df[\"designation_tr\"].isin(top_N_designation_tr) ,\"designation_tr\"] = \"None\"\n",
    "\n",
    "ohc_d = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "ohDesignation = ohc_d.fit_transform(df[\"designation_tr\"].values.reshape(-1,1)).toarray() dfOneHot_d = pd.DataFrame(ohDesignation, columns=[\"designationtr\" + str(ohcd.categories[0][i]) for i in range(len(ohcd.categories[0]))])\n",
    "\n",
    "df = pd.concat([df,dfOneHot_d], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggiungo i bit dei primi N designation a x eval\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "N = 300\n",
    "ohDesignation = ohc_d.transform(df_eval[\"designation_tr\"].values.reshape(-1,1)).toarray()\n",
    "dfOneHot_d = pd.DataFrame(ohDesignation, columns=[\"designation_tr_\" + str(ohc_d.categories_[0][i]) for i in range(len(ohc_d.categories_[0]))])\n",
    "\n",
    "df_eval = pd.concat([df_eval,dfOneHot_d], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo Vectorizer per x e x_eval\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "wpm = vectorizer.fit_transform(df[\"description\"].fillna(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggiungo a x i bit delle N parole più frequenti nella description \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", binary=True, use_idf=False,norm=False)\n",
    "\n",
    "wpm = vectorizer.fit_transform(df[\"description\"].fillna(\"\"))\n",
    "\n",
    "N = 500\n",
    "freq = sorted(zip(vectorizer.get_feature_names(), wpm.sum(axis=0).tolist()[0]),key=lambda x: x[1], reverse=True)[:N]\n",
    "\n",
    "words = [ word for word, _ in freq ]\n",
    "mask = [ w in words for w in vectorizer.get_feature_names() ]\n",
    "words_ = [ w for w in vectorizer.get_feature_names() if w in words ]\n",
    "df_words = pd.DataFrame(data=wpm[:, np.array(mask)].toarray(),columns=[f\"word_{word}\" for word in words_], index=df.index)\n",
    "\n",
    "df = pd.concat([df,df_words], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggiungo a x_eval i bit delle N parole più frequenti nella description \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "wpm = vectorizer.transform(df_eval[\"description\"].fillna(\"\"))\n",
    "\n",
    "\n",
    "df_words_eval = pd.DataFrame(data=wpm[:, np.array(mask)].toarray(),columns=[f\"word_{word}\" for word in words_], index=df_eval.index)\n",
    "\n",
    "df_eval = pd.concat([df_eval,df_words_eval], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Test tdidf description su x\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "N = 500\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", use_idf=True, max_features = N)\n",
    "\n",
    "wpm = vectorizer.fit_transform(df[\"description\"].fillna(\"\"))\n",
    "\n",
    "words = [ word for word, _ in freq ]\n",
    "mask = [ w in words for w in vectorizer.get_feature_names() ]\n",
    "words_ = [ w for w in vectorizer.get_feature_names() if w in words ]\n",
    "df_words = pd.DataFrame(data=wpm[:, np.array(mask)].toarray(),columns=[f\"word_{word}\" for word in words_], index=df.index)\n",
    "\n",
    "df_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regr = RandomForestRegressor(n_estimators=100, n_jobs=-1,max_features=\"sqrt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.iloc[:,9:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Test PCA \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X = df.iloc[:, 11:]\n",
    "y = df[\"quality\"]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_rescaled = scaler.fit_transform(X)\n",
    "#y_rescaled = scaler.fit_transform(y)\n",
    "\n",
    "pca = PCA(n_components = 0.99)\n",
    "pca.fit(X_rescaled)\n",
    "reduced = pca.transform(X_rescaled)\n",
    "\n",
    "reduced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#Predict con PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "            \n",
    "X_train, X_test, y_train, y_test = train_test_split(reduced, y, test_size=0.25, random_state=34)\n",
    "\n",
    "regr.fit(X_train,y_train)\n",
    "            \n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7080438026951108"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X = df.iloc[:, 11:]\n",
    "y = df[\"quality\"]\n",
    "            \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=34)\n",
    "\n",
    "regr.fit(X_train,y_train)\n",
    "            \n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.46834124e-02 8.28856827e-06 2.51292012e-05 ... 7.17989185e-04\n",
      " 3.73085942e-04 3.43013972e-04]\n"
     ]
    }
   ],
   "source": [
    "#prova\n",
    "print(regr.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Ricerca con grid search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X = df.iloc[:, 11:]\n",
    "y = df[\"quality\"]\n",
    "            \n",
    "param_grid = {\n",
    "\"n_estimators\": [100, 250],\n",
    "\"criterion\": [\"mse\"],\n",
    "\"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "\"random_state\": [42], # always use the samet random seed\n",
    "\"n_jobs\": [-1], # for parallelization\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(RandomForestRegressor(), param_grid, scoring=\"r2\", n_jobs=-1,cv=5)\n",
    "gs.fit(X, y)\n",
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import FunctionTransformer, PolynomialFeatures\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def evaluate_model(X, y, model, model_name):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,train_size=0.25,random_state=42,shuffle=True)\n",
    "    # plot the real function and the training points\n",
    "    LW = 2\n",
    "    #fig, ax = plt.subplots()\n",
    "    #ax.plot(X, y, color='cornflowerblue', linewidth=.5*LW, label=\"ground truth\")\n",
    "    #ax.scatter(X_train, y_train, color='navy', s=30, marker='o',label=\"training points\")\n",
    "    # predict the test points and plot them onto the chart\n",
    "    model.fit(X_train, y_train)\n",
    "    y_hat = model.predict(X_test)\n",
    "    #ax.plot(X_test, y_hat, linewidth=LW, label=name, color='r')\n",
    "    #fig.suptitle(f\"{f} approximated by {model_name}\")\n",
    "    #fig.legend()\n",
    "    return r2_score(y_test, y_hat)\n",
    "\n",
    "\n",
    "\n",
    "degree = 2\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    Ridge(random_state=42),\n",
    "    RandomForestRegressor(n_estimators=100,n_jobs=-1,max_features=\"sqrt\"),\n",
    "    make_pipeline(\n",
    "        make_column_transformer(\n",
    "            (FunctionTransformer(np.sin), [0]),\n",
    "            (PolynomialFeatures(degree), [0])\n",
    "        ),\n",
    "        LinearRegression()\n",
    "    ),\n",
    "    make_pipeline(\n",
    "        make_column_transformer(\n",
    "            (FunctionTransformer(np.sin), [0]),\n",
    "            (PolynomialFeatures(degree), [0])\n",
    "        ),\n",
    "        Ridge(alpha=1)\n",
    "    )\n",
    "]\n",
    "\n",
    "names = [\n",
    "    'linreg',\n",
    "    'ridge',\n",
    "    'rf',\n",
    "    f'sin+poly{degree}+linreg',\n",
    "    f'sin+poly{degree}+ridge'\n",
    "]\n",
    "\n",
    "\n",
    "t = PrettyTable()\n",
    "t.field_names = ['model', 'R2']\n",
    "X = df.iloc[:, 11:]\n",
    "y = df[\"quality\"]\n",
    "for model, name in zip(models, names):\n",
    "    print(model, name)\n",
    "    r2 = evaluate_model(X, y, model, name)\n",
    "    t.add_row([name, r2])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X = df.iloc[:, 11:]\n",
    "y = df[\"quality\"]\n",
    "\n",
    "regr_rf = RandomForestRegressor()\n",
    "parameters_rf = {'n_estimators':[50,100], 'n_jobs':[-1], \"max_features\":[\"sqrt\",\"log2\"], \"random_state\":[34]}\n",
    "clf_rf = GridSearchCV(regr_rf, parameters_rf, scoring=\"r2\",verbose=3)\n",
    "\n",
    "clf_rf.fit(X,y)\n",
    "print(clf_rf.best_params_)\n",
    "print(clf_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "X = df.iloc[:, 11:]\n",
    "y = df[\"quality\"]\n",
    "\n",
    "regr_rf = Ridge()\n",
    "parameters_rf = { \"alpha\":np.arange(0.1, 1.1, 0.2), \"fit_intercept\":[True,False],\"random_state\":[34]}\n",
    "clf_rf = GridSearchCV(regr_rf, parameters_rf, scoring=\"r2\",verbose=3)\n",
    "\n",
    "clf_rf.fit(X,y)\n",
    "print(clf_rf.best_params_)\n",
    "print(clf_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "X = df.iloc[:, 11:]\n",
    "y = df[\"quality\"]\n",
    "\n",
    "regr_rf = Lasso()\n",
    "parameters_rf = { \"alpha\":np.arange(0.1, 1.1, 0.2), \"fit_intercept\":[True,False],\"random_state\":[34]}\n",
    "clf_rf = GridSearchCV(regr_rf, parameters_rf, scoring=\"r2\",verbose=3)\n",
    "\n",
    "clf_rf.fit(X,y)\n",
    "print(clf_rf.best_params_)\n",
    "print(clf_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "freq[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(list(X.columns[11:]), regr.feature_importances_), key=lambda x: x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train[\"lat\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(list(df_eval.iloc[:,10:].columns)) - set(list(df.iloc[:, 11:].columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.drop(columns=[\"desi_quality_mean\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.iloc[:,10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.iloc[:, 11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features='sqrt', n_jobs=-1)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:, 11:]\n",
    "y = df[\"quality\"]\n",
    "            \n",
    "regr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval = df_eval.iloc[:,10:]\n",
    "\n",
    "y_eval = regr.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50.49, 46.62, 41.94, ..., 48.67, 29.54, 37.47])"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"my_submission.csv\",\"w\") as f:\n",
    "    f.write(\"Id,Predicted\\n\")\n",
    "    for i,result in enumerate(y_eval):\n",
    "        f.write(str(i) + \",\" + str(y_eval[i])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
